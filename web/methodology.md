# Bug Bounty Methodology

# Table of content
- [Finding Seed Domains](#finding-seed-domains)
  - Finding Acquisitions
  - ASN Enumeration
  - Reverse WHOIS
  - Ad/Analytics Relationship Mapping
  - Google Fu
- [Subdomain enumeration](#subdomain-enumeration)
  - Linked and JS Discovery
  - Subdomain Scraping
  - Subdomain Bruteforce

# Finding Seed Domains

## Finding Acquisitions
- https://www.crunchbase.com/

## ASN Enumeration
- Manual enumeration via https://bgp.he.net/
- Discover seed domains - `amass intel --asn`
- Automated enumeration
  - ASNLookup (maxmind.com dataset)
  - metabigor (bgp.he.net, asnlookup.com) 

## Reverse WHOIS
- https://whoxy.com/
- DOMLink (CLI of whoxy.com)

## Ad/Analytics Relationship Mapping
- https://buildwith.com/
- *getrelationship.py* (CLI by M4ll0k)

```bash
echo "tesla.com" | python3 getrelationship.com
```

## Google Fu
- "Copyright Text" inurl:tesla.com
- "Terms of Service Text" inurl:tesla.com
- "Privacy Policy Text" inurl:tesla.com

# Subdomain Enumeration
- [Linked and JS Discovery](#linked-and-js-discovery)
- [Subdomain Scraping](#subdomain-scraping)
- [Subdomain Bruteforce](#subdomain-bruteforce)

## Linked and JS Discovery

### Hakrawler
```bash
hakrawler -url tesla.com -hs -linkfinder
```

### GoSpirer
```bash
gospider -s https://tesla.com
```

- Pure bash linkfinder @ntrzz
```bash
curl -s $1 | grep -Eo "(http|https)://[a-zA-Z0-9./?=_-]*" | sort | uniq | grep ".js" > jslinks.txt; while IFS= read link; do python linkfinder.py -i "$link" -o cli; done < jslinks.txt | grep $2 | grep -v $3 | sort -n | uniq; rm -rf jslinks.txt
```

### Linked Discovery using Burp Suite Pro
- Set a scope item
  - Check "Use advanced scope controls"
  - Enter a term instead of an absolute domain name
  - Host or ip range: "keyword"
  - Site map
    - Filter by request type: Show only in-scope items
- Crawl all in-scope targets
  - Scan type: Crawl
  - Scan confgiruation
    - Crawl strategy - fastest
    - Never stop crawling due to application errors
  - Resource Pool
    - Name: "name"
    - Maximum concurrent requests: 50

### Subdomainizer
- Input JS files either from Burp or Hakrawler

```bash
python3 SubDomainizer.py -l jsfiles.txt -o js-subdomains.txt
```

- Finding JS files script @D0cK3rG33k
```bash
assetfinder site.com | gau|egrep -v '(.css|.png|.jpeg|.jpg|.svg|.gif|.wolf)'|while read url; do vars=$(curl -s $url | grep -Eo "var [a-zA-Zo-9_]+" |sed -e 's, 'var','"$url"?',g' -e 's/ //g'|grep -v '.js'|sed 's/.*/&=xss/g'):echo -e "\e[1;33m$url\n" "\e[1;32m$vars";done
```

- Extract endpoints from JS files @renniepak
```bash
cat main.js | grep -oh "\"\/[a-zA-Z0-9_/?=&]*\"" | sed -e 's/^"//' -e 's/"$//' | sort -u
```

### Subscraper by Cillian Collins
- For recursive analysis

## Subdomain Scraping
### Infrastructure sources
- Censys (requires an api key)
- Chaos (requires an api key)
- Robtex (requires an api key)
- DnsDB (requires an api key)
- Github (requires an api key)
- NetCraft
- PTRarchive
- Passive Total (requires an api key)
- Wayback Machine

### Search sources
- Google
- [BinaryEdge](https://binaryedge.io/)
- [Shodan]() (requires an api key)
- [Spyse]() (requires an api key)
- Zoomeye (requires an api key)
- Intelx (requires an api key)
- Yahoo
- Baidu
- Bing
- Ask
- DogPile

### Security sources
- VirusTotal
- SecurityTrails (requires an api key)
- F-Secure
- Hacker Target
- ThreatCrowd
- ThreatMiner
- ThreatBook (requires an api key)

### Certificate search
- crt.sh
- [CertSpotter](https://sslmate.com/certspotter/api/)
- certDB

### Subdomain scraping with Google
```
site:tesla.com -www.tesla.com
site:tesla.com -www.tesla.com -test.tesla.com
site:tesla.com -www.tesla.com -test.tesla.com -staging.teala.com
site:tesla.com -www.tesla.com -test.tesla.com -staging.example.com -prod.tesla.com
```

### Subdomain enumeration tools
```
amass enum -d tesla.com
subfinder -d tesla.com
findomain -t tesla.com
assetfinder --subs-only tesla.com
./lazyrecon.sh -d tesla.com
./lazyrecon.sh -d tesla.com -e excluded.tesla.com,other.tesla.com
```

- Get subdomains from rapiddns.io @andirrahmani1
```bash
curl -s "https://rapiddns.io/subdomain/$1?full=1#result" | grep "<td><a" | cut -d '"' -f 2 | grep http | cut -d '/' -f3 | sed 's/#results//g' | sort -u
```

- Get subdomains from bufferover.run @_ayoubfathi_
```bash
curl -s https://dns.bufferover.run/dns?q=.DOMAIN.com |jq -r .FDNS_A[]|cut -d',' -f2|sort -u
```

- Get subdomains from riddler.io @pikpikcu
```bash
curl -s "https://riddler.io/search/exportcsv?q=pld:domain.com" | grep -Po "(([\w.-]*)\.([\w]*)\.([A-z]))\w+" | sort -u
```

- Get subdomains from virustotal @pikpikcu
```bash

```

## Subdomain Bruteforce
```bash
./subbrute.py tesla.com
```

## Github Secrets
- Manual
  - https://github.com/obheda12/GitDorker/tree/master/Dorks

- Automated
```bash
python3 GitDorker.py -tf *tokensfile* -q org:teslamotors
```
